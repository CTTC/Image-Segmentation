// // **************************************************************************
// // Image Subtraction
// #include <opencv2/opencv.hpp>

// //C
// #include <stdio.h>
// //C++
// #include <iostream>
// #include <sstream>

// int main(int argc, char* argv[])
// {
//     cv::Mat bkg = cv::imread("/home/chentao/Pictures/bkg.jpg");
//     cv::Mat orig_img = cv::imread("/home/chentao/Pictures/box_bkg.jpg");
//     cv::Mat sub_img;
//     cv::absdiff(orig_img, bkg, sub_img);

//     cv::imshow("Background", bkg);
//     cv::imshow("Original", orig_img);
//     cv::imshow("Subtraction", sub_img);

//     cv::Mat thres_img;
//     cv::threshold(sub_img, thres_img, 50, 255.0, cv::THRESH_BINARY); 
//     cv::imshow("Threshold", thres_img);
//     while (1)
//     {
//         int keycode = cv::waitKey(20);
//         if ( keycode == 27 )
//             break;
//     }

// }


// // **************************************************************************
// //opencv
// #include "opencv2/imgcodecs.hpp"
// #include "opencv2/imgproc.hpp"
// #include "opencv2/videoio.hpp"
// #include <opencv2/highgui.hpp>
// #include <opencv2/video.hpp>
// //C
// #include <stdio.h>
// //C++
// #include <iostream>
// #include <sstream>
// using namespace cv;
// using namespace std;
// // Global variables
// Mat frame; //current frame
// Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
// Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
// int keyboard; //input from keyboard
// void help();
// void processVideo(char* videoFilename);
// void processImages(char* firstFrameFilename);
// void help()
// {
//     cout
//     << "--------------------------------------------------------------------------" << endl
//     << "This program shows how to use background subtraction methods provided by "  << endl
//     << " OpenCV. You can process both videos (-vid) and images (-img)."             << endl
//                                                                                     << endl
//     << "Usage:"                                                                     << endl
//     << "./bs {-vid <video filename>|-img <image filename>}"                         << endl
//     << "for example: ./bs -vid video.avi"                                           << endl
//     << "or: ./bs -img /data/images/1.png"                                           << endl
//     << "--------------------------------------------------------------------------" << endl
//     << endl;
// }
// int main(int argc, char* argv[])
// {
//     //print help information
//     help();
//     //check for the input parameter correctness
//     if(argc != 3) {
//         cerr <<"Incorret input list" << endl;
//         cerr <<"exiting..." << endl;
//         return EXIT_FAILURE;
//     }
//     //create GUI windows
//     namedWindow("Frame");
//     namedWindow("FG Mask MOG 2");
//     //create Background Subtractor objects
//     pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach
//     if(strcmp(argv[1], "-vid") == 0) {
//         //input data coming from a video
//         processVideo(argv[2]);
//     }
//     else if(strcmp(argv[1], "-img") == 0) {
//         //input data coming from a sequence of images
//         processImages(argv[2]);
//     }
//     else {
//         //error in reading input parameters
//         cerr <<"Please, check the input parameters." << endl;
//         cerr <<"Exiting..." << endl;
//         return EXIT_FAILURE;
//     }
//     //destroy GUI windows
//     destroyAllWindows();
//     return EXIT_SUCCESS;
// }
// void processVideo(char* videoFilename) {
//     //create the capture object
//     // VideoCapture capture(videoFilename);
//     VideoCapture capture(0);

//     if(!capture.isOpened()){
//         //error in opening the video input
//         cerr << "Unable to open video file: " << videoFilename << endl;
//         exit(EXIT_FAILURE);
//     }
//     //read input data. ESC or 'q' for quitting
//     while( (char)keyboard != 'q' && (char)keyboard != 27 ){
//         //read the current frame
//         if(!capture.read(frame)) {
//             cerr << "Unable to read next frame." << endl;
//             cerr << "Exiting..." << endl;
//             exit(EXIT_FAILURE);
//         }
//         //update the background model
//         pMOG2->apply(frame, fgMaskMOG2);
//         //get the frame number and write it on the current frame
//         stringstream ss;
//         rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
//                   cv::Scalar(255,255,255), -1);
//         ss << capture.get(CAP_PROP_POS_FRAMES);
//         string frameNumberString = ss.str();
//         putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
//                 FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
//         //show the current frame and the fg masks
//         imshow("Frame", frame);
//         imshow("FG Mask MOG 2", fgMaskMOG2);
//         //get the input from the keyboard
//         keyboard = waitKey( 30 );
//     }
//     //delete capture object
//     capture.release();
// }
// void processImages(char* fistFrameFilename) {
//     //read the first file of the sequence
//     frame = imread(fistFrameFilename);
//     if(frame.empty()){
//         //error in opening the first image
//         cerr << "Unable to open first image frame: " << fistFrameFilename << endl;
//         exit(EXIT_FAILURE);
//     }
//     //current image filename
//     string fn(fistFrameFilename);
//     //read input data. ESC or 'q' for quitting
//     while( (char)keyboard != 'q' && (char)keyboard != 27 ){
//         //update the background model
//         pMOG2->apply(frame, fgMaskMOG2);
//         //get the frame number and write it on the current frame
//         size_t index = fn.find_last_of("/");
//         if(index == string::npos) {
//             index = fn.find_last_of("\\");
//         }
//         size_t index2 = fn.find_last_of(".");
//         string prefix = fn.substr(0,index+1);
//         string suffix = fn.substr(index2);
//         string frameNumberString = fn.substr(index+1, index2-index-1);
//         istringstream iss(frameNumberString);
//         int frameNumber = 0;
//         iss >> frameNumber;
//         rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
//                   cv::Scalar(255,255,255), -1);
//         putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
//                 FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
//         //show the current frame and the fg masks
//         imshow("Frame", frame);
//         imshow("FG Mask MOG 2", fgMaskMOG2);
//         //get the input from the keyboard
//         keyboard = waitKey( 30 );
//         //search for the next image in the sequence
//         ostringstream oss;
//         oss << (frameNumber + 1);
//         string nextFrameNumberString = oss.str();
//         string nextFrameFilename = prefix + nextFrameNumberString + suffix;
//         //read the next frame
//         frame = imread(nextFrameFilename);
//         if(frame.empty()){
//             //error in opening the next image in the sequence
//             cerr << "Unable to open image frame: " << nextFrameFilename << endl;
//             exit(EXIT_FAILURE);
//         }
//         //update the path of the current frame
//         fn.assign(nextFrameFilename);
//     }
// }





// // **************************************************************************
// #include "opencv2/imgproc/imgproc.hpp"
// #include "opencv2/videoio/videoio.hpp"
// #include "opencv2/highgui/highgui.hpp"
// #include "opencv2/video/background_segm.hpp"
// #include <stdio.h>
// #include <string>
// using namespace std;
// using namespace cv;
// static void help()
// {
//     printf("\n"
//             "This program demonstrated a simple method of connected components clean up of background subtraction\n"
//             "When the program starts, it begins learning the background.\n"
//             "You can toggle background learning on and off by hitting the space bar.\n"
//             "Call\n"
//             "./segment_objects [video file, else it reads camera 0]\n\n");
// }
// static void refineSegments(const Mat& img, Mat& mask, Mat& dst)
// {
//     int niters = 3;
//     vector<vector<Point> > contours;
//     vector<Vec4i> hierarchy;
//     Mat temp;
//     dilate(mask, temp, Mat(), Point(-1,-1), niters);
//     erode(temp, temp, Mat(), Point(-1,-1), niters*2);
//     dilate(temp, temp, Mat(), Point(-1,-1), niters);
//     findContours( temp, contours, hierarchy, RETR_CCOMP, CHAIN_APPROX_SIMPLE );
//     dst = Mat::zeros(img.size(), CV_8UC3);
//     if( contours.size() == 0 )
//         return;
//     // iterate through all the top-level contours,
//     // draw each connected component with its own random color
//     int idx = 0, largestComp = 0;
//     double maxArea = 0;
//     for( ; idx >= 0; idx = hierarchy[idx][0] )
//     {
//         const vector<Point>& c = contours[idx];
//         double area = fabs(contourArea(Mat(c)));
//         if( area > maxArea )
//         {
//             maxArea = area;
//             largestComp = idx;
//         }
//     }
//     Scalar color( 0, 0, 255 );
//     drawContours( dst, contours, largestComp, color, FILLED, LINE_8, hierarchy );
// }
// int main(int argc, char** argv)
// {
//     VideoCapture cap;
//     bool update_bg_model = true;
//     CommandLineParser parser(argc, argv, "{help h||}{@input||}");
//     if (parser.has("help"))
//     {
//         help();
//         return 0;
//     }
//     string input = parser.get<std::string>("@input");
//     if (input.empty())
//         cap.open(0);
//     else
//         cap.open(input);
//     if( !cap.isOpened() )
//     {
//         printf("\nCan not open camera or video file\n");
//         return -1;
//     }
//     Mat tmp_frame, bgmask, out_frame;
//     cap >> tmp_frame;
//     if(tmp_frame.empty())
//     {
//         printf("can not read data from the video source\n");
//         return -1;
//     }
//     namedWindow("video", 1);
//     namedWindow("segmented", 1);
//     Ptr<BackgroundSubtractorMOG2> bgsubtractor=createBackgroundSubtractorMOG2();
//     bgsubtractor->setVarThreshold(10);
//     for(;;)
//     {
//         cap >> tmp_frame;
//         if( tmp_frame.empty() )
//             break;
//         bgsubtractor->apply(tmp_frame, bgmask, update_bg_model ? -1 : 0);
//         refineSegments(tmp_frame, bgmask, out_frame);
//         imshow("video", tmp_frame);
//         imshow("segmented", out_frame);
//         int keycode = waitKey(30);
//         if( keycode == 27 )
//             break;
//         if( keycode == ' ' )
//         {
//             update_bg_model = !update_bg_model;
//             printf("Learn background is in state = %d\n",update_bg_model);
//         }
//     }
//     return 0;
// }